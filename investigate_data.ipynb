{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import fiona\n",
    "import pandas as pd\n",
    "gpkg_suffix = \"_poly.gpkg\"\n",
    "gdb_suffix = \"_dbsn.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"download\"\n",
    "start_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(source_dir)\n",
    "provincies = [f.replace(\"_poly.gpkg\", \"\") for f in dir_list if \"_poly.gpkg\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_regioni = {'Matera': 'Basilicata',\n",
    "                     'Potenza': 'Basilicata',\n",
    "                     'Campobasso': 'Molise',\n",
    "                     'Isernia': 'Molise',\n",
    "                     'Pesaro e Urbino': 'Marche',\n",
    "                     'Caserta': 'Campania',\n",
    "                     'Catanzaro': 'Calabria',\n",
    "                     'Ancona': 'Marche',\n",
    "                     'Benevento': 'Campania',\n",
    "                     'Reggio di Calabria': 'Calabria',\n",
    "                     'Macerata': 'Marche',\n",
    "                     'Napoli': 'Campania',\n",
    "                     'Trapani': 'Sicilia',\n",
    "                     'Ascoli Piceno': 'Marche',\n",
    "                     'Avellino': 'Campania',\n",
    "                     'Palermo': 'Sicilia',\n",
    "                     'Massa Carrara': 'Toscana',\n",
    "                     'Salerno': 'Campania',\n",
    "                     'Messina': 'Sicilia',\n",
    "                     'Lucca': 'Toscana',\n",
    "                     \"L'Aquila\": 'Abruzzo',\n",
    "                     'Agrigento': 'Sicilia',\n",
    "                     'Pistoia': 'Toscana',\n",
    "                     'Teramo': 'Abruzzo',\n",
    "                     'Caltanissetta': 'Sicilia',\n",
    "                     'Firenze': 'Toscana',\n",
    "                     'Pescara': 'Abruzzo',\n",
    "                     'Enna': 'Sicilia',\n",
    "                     'Livorno': 'Toscana',\n",
    "                     'Chieti': 'Abruzzo',\n",
    "                     'Catania': 'Sicilia',\n",
    "                     'Pisa': 'Toscana',\n",
    "                     'Ragusa': 'Sicilia',\n",
    "                     'Arezzo': 'Toscana',\n",
    "                     'Foggia': 'Puglia',\n",
    "                     'Siracusa': 'Sicilia',\n",
    "                     'Siena': 'Toscana',\n",
    "                     'Bari': 'Puglia',\n",
    "                     'Grosseto': 'Toscana',\n",
    "                     'Taranto': 'Puglia',\n",
    "                     'Prato': 'Toscana',\n",
    "                     'Viterbo': 'Lazio',\n",
    "                     'Brindisi': 'Puglia',\n",
    "                     'Crotone': 'Calabria',\n",
    "                     'Vibo Valentia': 'Calabria',\n",
    "                     'Rieti': 'Lazio',\n",
    "                     'Lecce': 'Puglia',\n",
    "                     'Roma': 'Lazio',\n",
    "                     'Fermo': 'Marche',\n",
    "                     'Barletta-Andria-Trani': 'Puglia',\n",
    "                     'Perugia':'Umbria',\n",
    "                     'Terni':'Umbria',\n",
    "                     'Cagliari':'Sardegna',\n",
    "                     'Nuoro':'Sardegna',\n",
    "                     'Oristano':'Sardegna',\n",
    "                     'Sassari':'Sardegna',\n",
    "                     'Sud Sardegna':'Sardegna'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(osm_source,igm_source,prefix=source_dir + os.sep):\n",
    "    data = {}\n",
    "    building_source = {}\n",
    "    street_source = {}\n",
    "    osm_source = prefix + osm_source\n",
    "    igm_source = prefix + igm_source\n",
    "    igm_layers_list = fiona.listlayers(igm_source)\n",
    "    multipolygons_osm = gpd.read_file(osm_source,layer=\"multipolygons\",driver=\"GPKG\")\n",
    "    lines_osm = gpd.read_file(osm_source,layer=\"lines\",driver=\"GPKG\")\n",
    "    buildings_osm = multipolygons_osm.dropna(subset=['building'])\n",
    "    buildings_igm = gpd.read_file(igm_source,driver=\"FileGDB\",layer=\"edifc\")\n",
    "    buildings_igm = buildings_igm.replace(to_replace='.*=>.*', value='03', regex=True)\n",
    "    buildings_from_osm = buildings_igm[buildings_igm.meta_ist == \"03\"]\n",
    "    buildings_igm_source = pd.DataFrame(buildings_igm.meta_ist.value_counts()).reset_index().rename(columns={\"index\":\"meta_ist\",\"meta_ist\":\"totale\"})\n",
    "    buildings_igm_small = gpd.read_file(igm_source,driver=\"FileGDB\",layer=\"edi_min\")\n",
    "    buildings_igm_small = buildings_igm_small.replace(to_replace='.*=>.*', value='03', regex=True)\n",
    "    buildings_igm_small_source = pd.DataFrame(buildings_igm_small.meta_ist.value_counts()).reset_index().rename(columns={\"index\":\"meta_ist\",\"meta_ist\":\"totale\"})\n",
    "    igm_source_buildings = pd.concat([buildings_igm_source, buildings_igm_small_source]).groupby('meta_ist').sum().reset_index()\n",
    "    buildings_igm_small = gpd.read_file(igm_source,driver=\"FileGDB\",layer=\"edi_min\")\n",
    "    all_buildings_igm = pd.concat([buildings_igm_small.geometry, buildings_igm.geometry], ignore_index=True)\n",
    "    all_buildings_igm = gpd.GeoDataFrame(geometry=gpd.GeoSeries(all_buildings_igm))\n",
    "    buildings_from_osm = buildings_igm[buildings_igm.meta_ist == \"03\"]\n",
    "    area_buildings_from_osm = [0]\n",
    "    if buildings_from_osm.shape[0] > 0:\n",
    "        area_buildings_from_osm = buildings_from_osm.area.sum()\n",
    "    buildings_from_osm = buildings_igm_small[buildings_igm_small.meta_ist == \"03\"]\n",
    "    if buildings_from_osm.shape[0] > 0:\n",
    "        area_buildings_from_osm += buildings_from_osm.area.sum()\n",
    "    buildings_osm = buildings_osm.to_crs(all_buildings_igm.crs)\n",
    "    for idx in igm_source_buildings.meta_ist.unique():\n",
    "        #if idx.find(\"=>\") > -1:\n",
    "        #    building_source[\"buildings_source_03\"] = igm_source_buildings[igm_source_buildings.meta_ist == idx].totale.values[0]\n",
    "        #else:\n",
    "        building_source[\"buildings_source_\" + idx] = igm_source_buildings[igm_source_buildings.meta_ist == idx].totale.values[0]\n",
    "    add_igm_streets = False\n",
    "    add_igm_footway = False\n",
    "    add_igm_mix = False\n",
    "    streets_igm_sources = []\n",
    "    length_streets_from_osm = 0\n",
    "    if \"tr_str\" in igm_layers_list:\n",
    "        igm_streets = gpd.read_file(igm_source,layer=\"tr_str\")\n",
    "        igm_streets = igm_streets.replace(to_replace='.*=>.*', value='03', regex=True)\n",
    "        igm_strees_in_osm = igm_streets[igm_streets.meta_ist == \"03\"]\n",
    "        if igm_strees_in_osm.shape[0] > 0:\n",
    "            length_streets_from_osm = igm_strees_in_osm.length.sum()\n",
    "        add_igm_streets= True\n",
    "        streets_igm_sources.append(pd.DataFrame(igm_streets.meta_ist.value_counts()).reset_index().rename(columns={\"index\":\"meta_ist\",\"meta_ist\":\"totale\"}))\n",
    "    if \"ar_vms\" in igm_layers_list:    \n",
    "        igm_footway = gpd.read_file(igm_source,layer=\"ar_vms\")\n",
    "        igm_footway = igm_footway.replace(to_replace='.*=>.*', value='03', regex=True)\n",
    "        igm_strees_in_osm = igm_footway[igm_footway.meta_ist == \"03\"]\n",
    "        if igm_strees_in_osm.shape[0] > 0:\n",
    "            length_streets_from_osm += igm_strees_in_osm.length.sum()\n",
    "        add_igm_footway = True\n",
    "        streets_igm_sources.append(pd.DataFrame(igm_footway.meta_ist.value_counts()).reset_index().rename(columns={\"index\":\"meta_ist\",\"meta_ist\":\"totale\"}))\n",
    "    if \"el_vms\" in igm_layers_list:\n",
    "        igm_mix = gpd.read_file(igm_source,layer=\"el_vms\")\n",
    "        igm_mix = igm_mix.replace(to_replace='.*=>.*', value='03', regex=True)\n",
    "        igm_strees_in_osm = igm_mix[igm_mix.meta_ist == \"03\"]\n",
    "        if igm_strees_in_osm.shape[0] > 0:\n",
    "            length_streets_from_osm += igm_strees_in_osm.length.sum()\n",
    "        add_igm_mix = True\n",
    "    streets_igm_sources.append(pd.DataFrame(igm_mix.meta_ist.value_counts()).reset_index().rename(columns={\"index\":\"meta_ist\",\"meta_ist\":\"totale\"}))\n",
    "    lines_osm = lines_osm.to_crs(igm_streets.crs)\n",
    "    if add_igm_streets:\n",
    "        all_streets_igm = igm_streets\n",
    "    if add_igm_footway:\n",
    "        all_streets_igm = pd.concat([all_streets_igm.geometry, igm_footway.geometry], ignore_index=True)\n",
    "    if add_igm_mix:\n",
    "        all_streets_igm = pd.concat([all_streets_igm.geometry, igm_mix.geometry], ignore_index=True)\n",
    "    count_streets_igm_sources = pd.DataFrame()\n",
    "    for strestreets_igm_source in streets_igm_sources:\n",
    "        count_streets_igm_sources = pd.concat([count_streets_igm_sources, strestreets_igm_source])\n",
    "    count_streets_igm_sources = count_streets_igm_sources.groupby('meta_ist').sum().reset_index()\n",
    "    for idx in count_streets_igm_sources.meta_ist.unique():\n",
    "        #if idx.find(\"=>\") > -1:\n",
    "        #    street_source[\"streets_source_03\"] = count_streets_igm_sources[count_streets_igm_sources.meta_ist == idx].totale.values[0]\n",
    "        #else:\n",
    "        street_source[\"streets_source_\" + idx] = count_streets_igm_sources[count_streets_igm_sources.meta_ist == idx].totale.values[0]\n",
    "    all_streets_igm= gpd.GeoDataFrame(geometry=gpd.GeoSeries(all_streets_igm))  \n",
    "    osm_streets = lines_osm[lines_osm.highway.isin(['unclassified','trunk_link','trunk','tertiary_link','tertiary', 'service', 'secondary_link','secondary','road','residential','primary_link','primary','pedestrian','living_street','construction'])]\n",
    "    osm_footways = lines_osm[lines_osm.highway.isin(['footway','cycleway','track','path','pedestrian','steps'])]\n",
    "    all_streets_osm = pd.concat([osm_footways.geometry, osm_streets.geometry], ignore_index=True)\n",
    "    all_streets_osm= gpd.GeoDataFrame(geometry=gpd.GeoSeries(all_streets_osm))    \n",
    "    data['osm_buildings'] = buildings_osm\n",
    "    data['igm_buildings'] = all_buildings_igm\n",
    "    #data['area_buildings_from_osm'] = [area_buildings_from_osm]\n",
    "    #data['length_streets_from_osm'] = [length_streets_from_osm]\n",
    "    data['igm_streets'] = all_streets_igm\n",
    "    data['osm_streets'] = all_streets_osm\n",
    "    data['igm_streets_sources'] = street_source \n",
    "    data['igm_buildigs_sources'] = building_source\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverageBuildings(buildings_osm,buildings_igm):\n",
    "    data = {}\n",
    "    points_buildings_osm = buildings_osm.geometry.representative_point()\n",
    "    points_buildings_osm = gpd.GeoDataFrame(geometry=gpd.GeoSeries(points_buildings_osm))\n",
    "    osm_buildings_in_igm = gpd.sjoin(buildings_igm, points_buildings_osm, predicate='contains')\n",
    "    area_osm_buildings_in_igm  = buildings_osm[buildings_osm.index.isin(osm_buildings_in_igm.index.unique())].geometry.area.sum()\n",
    "    data['area_osm_buildings'] = [buildings_osm.geometry.area.sum()] \n",
    "    data['area_igm_buildings'] = [buildings_igm.geometry.area.sum()]   \n",
    "    data['area_osm_in_igm_buildings'] = [area_osm_buildings_in_igm]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverageStreets(streets_osm,streets_igm):\n",
    "    data = {}\n",
    "    common_streets = gpd.sjoin(streets_osm, streets_igm, predicate='intersects')    \n",
    "    length = streets_osm[streets_osm.index.isin(common_streets.index.unique())].geometry.length.sum()\n",
    "    data['osm_in_igm_streets_length'] = [length]\n",
    "    data['osm_streets_length'] = [streets_osm.geometry.length.sum()]\n",
    "    data['igm_streets_length'] = [streets_igm.geometry.length.sum()]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuoro\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'left_df' should be GeoDataFrame, got <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m data_province \u001b[39m=\u001b[39m getdata(province\u001b[39m+\u001b[39mgpkg_suffix,province\u001b[39m+\u001b[39mgdb_suffix)\n\u001b[1;32m      5\u001b[0m data_buildings \u001b[39m=\u001b[39m coverageBuildings(data_province[\u001b[39m'\u001b[39m\u001b[39mosm_buildings\u001b[39m\u001b[39m'\u001b[39m],data_province[\u001b[39m'\u001b[39m\u001b[39migm_buildings\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m data_streets \u001b[39m=\u001b[39m coverageStreets(province\u001b[39m+\u001b[39;49mgpkg_suffix,province\u001b[39m+\u001b[39;49mgdb_suffix)\n\u001b[1;32m      7\u001b[0m data_buildings\u001b[39m.\u001b[39mupdate(data_streets)\n\u001b[1;32m      8\u001b[0m data_buildings[\u001b[39m'\u001b[39m\u001b[39mprovince\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [province]\n",
      "Cell \u001b[0;32mIn [80], line 3\u001b[0m, in \u001b[0;36mcoverageStreets\u001b[0;34m(streets_osm, streets_igm)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcoverageStreets\u001b[39m(streets_osm,streets_igm):\n\u001b[1;32m      2\u001b[0m     data \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m     common_streets \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39;49msjoin(streets_osm, streets_igm, predicate\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mintersects\u001b[39;49m\u001b[39m'\u001b[39;49m)    \n\u001b[1;32m      4\u001b[0m     length \u001b[39m=\u001b[39m streets_osm[streets_osm\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39misin(common_streets\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39munique())]\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mlength\u001b[39m.\u001b[39msum()\n\u001b[1;32m      5\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mosm_in_igm_streets_length\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [length]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/tools/sjoin.py:122\u001b[0m, in \u001b[0;36msjoin\u001b[0;34m(left_df, right_df, how, predicate, lsuffix, rsuffix, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     first \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys()))\n\u001b[1;32m    120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msjoin() got an unexpected keyword argument \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfirst\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m _basic_checks(left_df, right_df, how, lsuffix, rsuffix)\n\u001b[1;32m    124\u001b[0m indices \u001b[39m=\u001b[39m _geom_predicate_query(left_df, right_df, predicate)\n\u001b[1;32m    126\u001b[0m joined \u001b[39m=\u001b[39m _frame_join(indices, left_df, right_df, how, lsuffix, rsuffix)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/tools/sjoin.py:150\u001b[0m, in \u001b[0;36m_basic_checks\u001b[0;34m(left_df, right_df, how, lsuffix, rsuffix)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Checks the validity of join input parameters.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \n\u001b[1;32m    134\u001b[0m \u001b[39m`how` must be one of the valid options.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m    right index suffix\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(left_df, GeoDataFrame):\n\u001b[0;32m--> 150\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    151\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft_df\u001b[39m\u001b[39m'\u001b[39m\u001b[39m should be GeoDataFrame, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(left_df))\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(right_df, GeoDataFrame):\n\u001b[1;32m    155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mright_df\u001b[39m\u001b[39m'\u001b[39m\u001b[39m should be GeoDataFrame, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(right_df))\n\u001b[1;32m    157\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: 'left_df' should be GeoDataFrame, got <class 'str'>"
     ]
    }
   ],
   "source": [
    "data_analysis = pd.DataFrame()\n",
    "for province in provincies:\n",
    "    print(province)\n",
    "    data_province = getdata(province+gpkg_suffix,province+gdb_suffix)\n",
    "    data_buildings = coverageBuildings(data_province['osm_buildings'],data_province['igm_buildings'])\n",
    "    data_streets = coverageStreets(province+gpkg_suffix,province+gdb_suffix)\n",
    "    data_buildings.update(data_streets)\n",
    "    data_buildings['province'] = [province]\n",
    "    data_buildings['region'] = [province_regioni[province]]\n",
    "    data_analysis = pd.DataFrame(data=data_buildings)\n",
    "    data_analysis.to_parquet(source_dir + os.sep + province+\".parquet\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
